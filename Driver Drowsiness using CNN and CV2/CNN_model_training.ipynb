{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5328da",
   "metadata": {},
   "source": [
    "<h1><center>Driver Drowsiness Detection</center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb405a",
   "metadata": {},
   "source": [
    "**Importing the libraries for the model building:**\n",
    "<br>\n",
    "<br>\n",
    "**import os**:this module will provide functions for creating and removing a directory (folder), fetching its contents, changing and identifying the current directory, etc. We have to import the os module to interact with the underlying operating system.\n",
    "<br>\n",
    "**keras.preprocessing import image**: used for real-time data augmentation on image data.\n",
    "<br>\n",
    "**matplotlib.pyplot as plt**: used for generating visualizations\n",
    "<br>\n",
    "**import numpy as np**: used for array related functions\n",
    "<br>\n",
    "**keras.utils.np_utils import to_categorical**: used to Convert a class vector (integers) to binary class matrix\n",
    "<br>\n",
    "**import random**:used for pseudo-random number generators for various distributions\n",
    "<br>\n",
    "**import shutil**:provides support for file copying and removal\n",
    "<br>\n",
    "**keras.models import Sequential**: Sequential model is used for a plain stack of layers where each layer has one input tensor and one output tensor.\n",
    "<br>\n",
    "**Dropout**: is a technique where randomly selected neurons are ignored during training to prevent overfitting\n",
    "<br>\n",
    "**Conv2D**:is a 2D Convolution Layer, this layer creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n",
    "<br>\n",
    "**Flatten**: it reshapes the tensor to have the shape that is equal to the number of elements contained in tensor non including the batch dimension\n",
    "<br>\n",
    "**Dense**: a dense layer is deeply connected with its preceding layer which means the neurons of the layer are connected to every neuron of its preceding layer.\n",
    "<br>\n",
    "**MaxPooling2D**: Max pooling selects the brighter pixels from the image. It is used to downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size ) for each channel of the input.\n",
    "<br>\n",
    "**BatchNormalization**: it is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847d6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random,shutil\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724f509",
   "metadata": {},
   "source": [
    "We are defining a function generator to genearte the train and test batch and rescalae and categorize the data. The data we are using here is a already available data set and can be fteched from [here](https://drive.google.com/drive/folders/1nTb-_PURK8XO8yv36MzFoviJQ6csvniL?usp=sharing). The data is divided into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54b0475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1234 images belonging to 2 classes.\n",
      "Found 218 images belonging to 2 classes.\n",
      "Steps Per Epoch= 38 Test Steps= 6\n"
     ]
    }
   ],
   "source": [
    "def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),class_mode='categorical' ):\n",
    "\n",
    "    return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',class_mode=class_mode,target_size=target_size)\n",
    "\n",
    "batch_size= 32\n",
    "target_size=(24,24)\n",
    "train_batch= generator('data/train',shuffle=True, batch_size=batch_size,target_size=target_size)\n",
    "test_batch= generator('data/test',shuffle=True, batch_size=batch_size,target_size=target_size)\n",
    "steps_per_epoch= len(train_batch.classes)//batch_size\n",
    "test_steps = len(test_batch.classes)//batch_size\n",
    "print(f'Steps Per Epoch= {steps_per_epoch}',f'Test Steps= {test_steps}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26bf0d",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network** is a deep neural network which performs extremely well for image classification purposes. A CNN basically consists of an input layer, an output layer and a hidden layer which can have multiple layers. A convolution operation is performed on these layers using a filter that performs 2D matrix multiplication on the layer and filter.\n",
    "\n",
    "The Sequential CNN model we are going to define will consist of the following layers:\n",
    "\n",
    "Convolutional layer; 32 neurons, kernel size 3\n",
    "<br>\n",
    "Convolutional layer; 32 neurons, kernel size 3\n",
    "<br>\n",
    "Convolutional layer; 64 neurons, kernel size 3\n",
    "<br>\n",
    "Fully connected layer; 128 neurons\n",
    "<br>\n",
    "The final layer is also a fully connected layer with 2 neurins.\n",
    "<br>\n",
    "We have used **Relu** activation function in all the layers except the output layer in which we have used **Softmax**.\n",
    "\n",
    "**ReLU stands for Rectified Linear Unit**: it is a linear function that will give the input as output directly if it is positive, otherwise, it will give output as zero.\n",
    "**SoftMax**: it is a type of squashing function and limits the output of the function into the range 0 to 1. This allows the output to be interpreted directly as a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68b9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    Conv2D(32,(3,3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb05b00f",
   "metadata": {},
   "source": [
    "We have used Optimizer **'Adam'**: *Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models. Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.*\n",
    "<br>\n",
    "Loss funtion **'Categorical_crossentropy'**: *Categorical crossentropy is a loss function that is used in multi-class classification tasks. These are tasks where an example can only belong to one out of many possible categories, and the model must decide which one.*\n",
    "<br>\n",
    "We will fit and compile the model with train_batch and do the validation with test_batch.\n",
    "We are saving the model as an .h5 file so that we can call the model and provide the video feed as input to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad53ab13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "38/38 [==============================] - 7s 169ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.2180 - val_accuracy: 0.9323\n",
      "Epoch 2/15\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 0.1699 - accuracy: 0.9326 - val_loss: 0.1291 - val_accuracy: 0.9531\n",
      "Epoch 3/15\n",
      "38/38 [==============================] - 5s 145ms/step - loss: 0.1371 - accuracy: 0.9434 - val_loss: 0.1351 - val_accuracy: 0.9688\n",
      "Epoch 4/15\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.1097 - accuracy: 0.9601 - val_loss: 0.1176 - val_accuracy: 0.9531\n",
      "Epoch 5/15\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.0829 - accuracy: 0.9734 - val_loss: 0.0889 - val_accuracy: 0.9583\n",
      "Epoch 6/15\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.0539 - accuracy: 0.9817 - val_loss: 0.0581 - val_accuracy: 0.9792\n",
      "Epoch 7/15\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.0427 - accuracy: 0.9850 - val_loss: 0.0757 - val_accuracy: 0.9688\n",
      "Epoch 8/15\n",
      "38/38 [==============================] - 6s 146ms/step - loss: 0.0404 - accuracy: 0.9842 - val_loss: 0.0480 - val_accuracy: 0.9688\n",
      "Epoch 9/15\n",
      "38/38 [==============================] - 6s 144ms/step - loss: 0.0290 - accuracy: 0.9859 - val_loss: 0.0511 - val_accuracy: 0.9740\n",
      "Epoch 10/15\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 0.0431 - val_accuracy: 0.9844\n",
      "Epoch 11/15\n",
      "38/38 [==============================] - 5s 145ms/step - loss: 0.0483 - accuracy: 0.9817 - val_loss: 0.0472 - val_accuracy: 0.9740\n",
      "Epoch 12/15\n",
      "38/38 [==============================] - 5s 144ms/step - loss: 0.0494 - accuracy: 0.9803 - val_loss: 0.0752 - val_accuracy: 0.9688\n",
      "Epoch 13/15\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 0.0744 - val_accuracy: 0.9583\n",
      "Epoch 14/15\n",
      "38/38 [==============================] - 5s 145ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.0678 - val_accuracy: 0.9792\n",
      "Epoch 15/15\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.0125 - accuracy: 0.9950 - val_loss: 0.0457 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_batch, validation_data=test_batch,epochs=15,steps_per_epoch=steps_per_epoch ,validation_steps=test_steps)\n",
    "\n",
    "model.save('models/cnndd.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe32c51",
   "metadata": {},
   "source": [
    "We have attained an accuracy of 96.88 percent in 15 epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
